{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification with PyTorch (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Declaring Dataloader [load data in NN a/c to batch size (if given)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ris = resize_image_size = 64\n",
    "train_data_path=\"/home/garvit/work_area/zone/Anaconda_WorkSpace/jupyter/PyTorch practice/PyTorch Book/chapter2/dataset/training_set/\"\n",
    "test_data_path=\"/home/garvit/work_area/zone/Anaconda_WorkSpace/jupyter/PyTorch practice/PyTorch Book/chapter2/dataset/test_set/\"\n",
    "\n",
    "# declaring some trasformations on images for NN feed i.e Scaling images, converting into tensors e.t.c\n",
    "transformations = transforms.Compose([transforms.Resize((ris,ris)),\n",
    "                                 transforms.ToTensor(),\n",
    "                                 transforms.Normalize(mean= [0.485, 0.456, 0.406],\n",
    "                                                      std = [0.229, 0.224, 0.225])])\n",
    "\n",
    "# applying above transformations\n",
    "train_data = torchvision.datasets.ImageFolder(root=train_data_path, transform=transformations)\n",
    "# val_data   = torchvision.datasets.ImageFolder(root = val_data_path, transform=transforms) \n",
    "test_data  = torchvision.datasets.ImageFolder(root = test_data_path, transform=transformations)\n",
    "\n",
    "\n",
    "# declaring DataLoader (load data in NN a/c to batch size if given)\n",
    "BatchSize = 48\n",
    "train_data_loader = DataLoader(dataset=train_data, batch_size = BatchSize, shuffle=True )\n",
    "# val_data_loader = DataLoader(dataset=val_data, batch_size = BatchSize)\n",
    "test_data_loader = DataLoader(dataset=test_data, batch_size = BatchSize, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a CNN Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=5, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU())\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(64*64*5,4096),\n",
    "            nn.Linear(4096, 1024),\n",
    "            nn.Linear(1024,2))        \n",
    "        \n",
    "    def forward(self, x):\n",
    "#         x.view(-1, 3*ris*ris)\n",
    "        x = self.features(x)\n",
    "        x = torch.flatten(x,1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "        \n",
    "\n",
    "cnnNet = CNNNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam, SGD\n",
    "optimizer = SGD(params=cnnNet.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking for GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNNNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 5, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=20480, out_features=4096, bias=True)\n",
       "    (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "    (2): Linear(in_features=1024, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\") \n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "cnnNet.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Training Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimiser, loss_fn, train_loader, val_loader, epochs=1, device='cpu'):\n",
    "    for epoch in range(epochs):\n",
    "            training_loss = 0\n",
    "            valid_loss = 0\n",
    "            model.train()\n",
    "            for batch in train_loader:\n",
    "#                 print(f\"training batch: {batch}\")\n",
    "                optimizer.zero_grad()\n",
    "                inputs, target = batch\n",
    "#                 print(inputs)\n",
    "                inputs = inputs.to(device)\n",
    "                target = target.to(device)\n",
    "                output = model(inputs)\n",
    "                loss = loss_fn(output, target)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                training_loss += loss.data.item()\n",
    "            training_loss /= len(train_loader.dataset)\n",
    "            \n",
    "            model.eval()\n",
    "            num_correct = 0\n",
    "            num_examples = 0\n",
    "            for batch in val_loader:\n",
    "                inputs, target = batch\n",
    "                inputs = inputs.to(device)\n",
    "                output = model(inputs)\n",
    "                loss = loss_fn(output, target)\n",
    "                valid_loss += loss.data.item()\n",
    "                correct = torch.eq(torch.max(F.softmax(output), dim=1)[1], target).view(-1)\n",
    "                num_correct += torch.sum(correct).item()\n",
    "                num_examples += correct.shape[0]\n",
    "            valid_loss /= len(val_loader.dataset)\n",
    "\n",
    "            print(f'Epoch: {epoch+1},  Training Loss: {round(training_loss,3)}, \\\n",
    "            Validation Loss: {round(valid_loss,3)}, \\\n",
    "            accuracy = {round(num_correct / num_examples,2)}')            \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enabling Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/garvit/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1,  Training Loss: 0.014,             Validation Loss: 0.014,             accuracy = 0.57\n",
      "Epoch: 2,  Training Loss: 0.013,             Validation Loss: 0.013,             accuracy = 0.66\n",
      "Epoch: 3,  Training Loss: 0.013,             Validation Loss: 0.013,             accuracy = 0.67\n",
      "Epoch: 4,  Training Loss: 0.012,             Validation Loss: 0.013,             accuracy = 0.65\n",
      "Epoch: 5,  Training Loss: 0.012,             Validation Loss: 0.013,             accuracy = 0.66\n",
      "Training time: 0:11:12.68\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time() \n",
    "train(cnnNet, optimizer,nn.CrossEntropyLoss(), train_data_loader,test_data_loader, epochs=5, device=device)\n",
    "time_took = f\"{time.time() - start_time!r}\"\n",
    "time_took = str(datetime.timedelta(seconds=round(float(time_took),2))).rstrip('0')\n",
    "print(f\"Training time: {time_took}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
